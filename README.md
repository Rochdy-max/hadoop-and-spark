# hadoop-and-spark
This project aims to setup Hadoop and Spark for common usage.

It uses Docker to provide isolation for one master node and two worker nodes. 
